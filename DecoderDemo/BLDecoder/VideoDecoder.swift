//
//  VideoDecoder.swift
//  Aries
//
//  Created by liangwei on 2023/3/7.
//  Copyright ¬© 2023 Pinguo. All rights reserved.
//

import UIKit
import AVFoundation

/// ËßÜÈ¢ëËß£Á†ÅÂô®
class VideoDecoder {
    
    static let device = MTLCreateSystemDefaultDevice()
    
    /// ËßÜÈ¢ëËß£Á†ÅÁõ∏ÂÖ≥Â±ûÊÄß
    private var asset: AVAsset?
    private var videoTrack: AVAssetTrack?
    private(set) var videoOriginalFPS: CGFloat

    private var reader: AVAssetReader?
    private var videoTrackOutput: AVAssetReaderTrackOutput?
    private var outputSetting: [String: Any] = [:]
        
    /// Ââç‰∏ÄÊ¨°decodeÊàêÂäüÁöÑÊó∂Èó¥Êà≥
    private var latestDecodeTime: Double = 0
    
    /// ÂΩìÂâçÈúÄË¶ÅdecodeÁöÑÊó∂Èó¥Êà≥
    private var currentDecodeTime: Double = -1
    
    /// Ê†áËÆ∞‰øÆÊîπ‰∫ÜËß£Á†ÅÂô®ËæìÂá∫Â∞∫ÂØ∏Ôºå‰∏ãÊ¨°Ëß£Á†ÅÊó∂ÈúÄË¶ÅÈáçÂª∫Ëß£Á†ÅÂô®
    private var outputSizeChanged: Bool = false
    
    /// ËµÑÊ∫êÊó∂Èïø
    private(set) var assetDuration: Double = 0
    
    private(set) var decodeBuffer: CMSampleBuffer?
    
    private var decodeTexture: MTLTexture?
    
    private var identifier: String
    
    private var uri: String
    
    private var cache = MediaMetaCache()
        
    /// ‰∏ÄÂ∏ßÁöÑÊó∂Èïø
    let oneFrameTime: Double
    
    lazy var textureCache: CVMetalTextureCache? = {
        var cache: CVMetalTextureCache?
        CVMetalTextureCacheCreate(kCFAllocatorDefault, nil, Self.device!, nil, &cache)
        return cache
    }()
    
    /// Ëß£Á†ÅËæìÂá∫Â∞∫ÂØ∏
    var outputSize: CGSize = .zero
    
    var meta: MediaMeta? {
        return cache.meta(for: uri, isVideo: true)
    }
    
    // MARK: Initialized Method
    required init(uri: String, key: String) {
        self.uri = uri
        identifier = key
        oneFrameTime = 1.0 / CGFloat(30)
        if let meta = cache.meta(for: uri, isVideo: true) {
            asset = meta.videoAsset
            videoTrack = meta.videoTrack
            let nominalFrameRate = CGFloat(videoTrack?.nominalFrameRate ?? 0)
            if nominalFrameRate > 0 {
                /// Êüê‰∫õËßÜÈ¢ënominalFrameRateËØªÂá∫Êù•ËßÜÈ¢ëÂ∏ßÁéá29.99998‰∏çÂáÜÁ°ÆÔºådecodeÊñπÊ≥ï‰∏≠‰ΩøÁî®videoOriginalFPSÂêë‰∏ãÂç°Â∏ßÂØºËá¥0.03333333333333Ë¢´Âç°ÊàêÁ¨¨0Â∏ßÔºåÂØºËá¥Ëß£Á†ÅÁîªÈù¢ÂíåËßÜÈ¢ëÁîªÈù¢‰∏ç‰∏ÄËá¥
                videoOriginalFPS = nominalFrameRate.precised(3)
            }
            else {
                videoOriginalFPS = CGFloat(30)
            }

            if let track = videoTrack {
                assetDuration = track.timeRange.duration.seconds
            }
        }
        else {
            videoOriginalFPS = CGFloat(30)
        }
        outputSize = meta?.realSize ?? .zero
    }
    
    
    deinit {
        clear()
        print("ü§ñ VideoDecoder deinit.")
    }
    
    func updateOutputSize(_ size: CGSize) {
        guard !size.equalTo(outputSize) else {
            return
        }
        
        decodeTexture = nil
        outputSize = size
        outputSizeChanged = true
    }

    /// Ëß£Á†ÅÊåáÂÆö‰ΩçÁΩÆÁöÑÂ∏ßÊï∞ÊçÆÂ∞ÅË£ÖÊàêMTLTextureËøõË°åËøîÂõû
    /// - Parameter targetTime: ÂæÖËß£Á†Å‰ΩçÁΩÆ
    /// - Returns: ÊåáÂÆö‰ΩçÁΩÆÁöÑÂ∏ßÊï∞ÊçÆÁ∫πÁêÜ‰ø°ÊÅØ
    func decode(_ targetTime: Double) -> CMSampleBuffer? {
        let targetTime: CGFloat = targetTime
        guard !outputSize.equalTo(.zero) else {
            return nil
        }
        
        // Âú®Âä®ÊÄÅÂ∏ßÁéáÁöÑÊÉÖÂÜµ‰∏ãÔºå‰∫ßÁîüÁöÑËíôÁâàËßÜÈ¢ëÂπ≥ÂùáÂ∏ßÁéáÂíåËßÜÈ¢ëÊúâËØØÂ∑ÆÔºåÂêë‰∏ãÂç°Â∏ßÂèØ‰ª•ÈÅøÂÖçÁªùÂ§ßÈÉ®ÂàÜÁöÑËØØÂ∑ÆÊÉÖÂÜµ
        let correctTime = targetTime > 0.0 ? targetTime.floorMatchFrameValue(fps: videoOriginalFPS) : 0.0
        
        objc_sync_enter(self)
        let startTime = CFAbsoluteTimeGetCurrent()
        defer {
            objc_sync_exit(self)
            let endTime = CFAbsoluteTimeGetCurrent()
            print("ü¶Å VideoDecoder decode cost: \((endTime - startTime) * 1000)ms")
        }
        
        // ÊòØÂê¶ÊòØÂú®ÂæÄÂâç(ÂæÄÂè≥)ÊªëÂä® - ÂÄíÁùÄÊªëÂä®
        let isForward = latestDecodeTime > correctTime
        // Â¶ÇÊûúÂíå‰∏äÊ¨°Â∑≤Ëß£Á†ÅÊó∂Èó¥Áõ∏Á≠âÔºåÂàôÁõ¥Êé•ËøîÂõû‰∏äÊ¨°ÁöÑÁ∫πÁêÜ
        if latestDecodeTime == correctTime, let curTexture = decodeTexture {
            return decodeBuffer
        }
        /* ‰ª•‰∏ãÂá†ÁßçÊÉÖÂÜµÈúÄË¶ÅÈáçÊñ∞ÊûÑÈÄ†Ëß£Á†ÅÂô®
           1. -1: Ë°®Á§∫Á¨¨‰∏ÄÊ¨°ËøõÂÖ•Ëß£Á†Å
           2. isForward: Ë°®Á§∫ÂÄíÊîæÈúÄË¶ÅÈáçÊñ∞ÂºÄÂßãËß£Á†Å
           3. outputSizeChanged: Ë°®Á§∫È¢ÑËßàÂ∞∫ÂØ∏Ë¢´‰øÆÊîπ
           4. ÊòØÂê¶Ë¢´Á≥ªÁªü‰∏≠Êñ≠
           5. ÂºÇÂ∏∏‰∏ãËß£Á†ÅÂô®Ê≤°ÂàõÂª∫
           6. ÂæÖËß£Á†Å‰ΩçÁΩÆÂíåÂΩìÂâçËßÜÈ¢ëÁúüÂÆûËß£Á†Å‰ΩçÁΩÆË∂ÖËøá2s */
        var interuptBySys: Bool = false
        if let error = self.reader?.error as? NSError, error.code == -11847 {
            interuptBySys = true
        }
        
        if latestDecodeTime == -1 ||
            isForward ||
            outputSizeChanged ||
            interuptBySys ||
            reader?.status == .failed ||
            (correctTime - latestDecodeTime) >= 2.0 {
            // ÂàõÂª∫Êó∂ÔºåÂêëÂâçÂ§öËÆæÁΩÆ‰∏ÄÂ∏ß
            var startTime = (correctTime - oneFrameTime) > 0 ? (correctTime - oneFrameTime) : 0.0
            if self.assetDuration - targetTime < 0.5 {
                startTime = (startTime - 0.5) > 0 ? (startTime - 0.5) : 0.0
            }
            
            createNewReader(startTime)
            self.decodeBuffer = nil
            outputSizeChanged = false
        }
        
        guard let track = videoTrack else {
            return nil
        }
        
        latestDecodeTime = correctTime
        // ÊòØÂê¶‰ΩøÁî®Áõ∏ÂêåÂ∏ß
        var useSameBuffer: Bool = false
        if let curBuffer = decodeBuffer {
            let curSampleTime: CMTime = CMSampleBufferGetOutputPresentationTimeStamp(curBuffer)
            if CMTIME_IS_INVALID(curSampleTime) {
                useSameBuffer = false
            }
            // Â¶ÇÊûúÂΩìÂâçbufferÊó∂Èó¥Â§ß‰∫éÁõÆÊ†áÊó∂Èó¥ÔºåÊàñËÄÖÊòØÂΩìÂâçÊòØÊúÄÂêé‰∏ÄÂ∏ßÔºåÂπ∂‰∏îÂΩìÂâçbufferÁöÑÊó∂Èó¥ÂíåÁõÆÂâçÁõ∏Â∑Æ‰∏çË∂ÖËøá1Â∏ßÔºåÂ∞±‰ΩøÁî®ÂΩìÂâçÂ∏ß
            if isMatchFrame(targetTime: correctTime, decodeTime: curSampleTime) {
                useSameBuffer = true
            }
        }
        
        if useSameBuffer {
            return decodeBuffer
        }

        guard let reader = self.reader, let output = self.videoTrackOutput else {
            return nil
        }
        
        while reader.status == .reading && track.nominalFrameRate > 0 {
            let beginTime = CFAbsoluteTimeGetCurrent()
            guard let buffer = output.copyNextSampleBuffer() else {
                break
            }
            let endTime = CFAbsoluteTimeGetCurrent()
            print("ü¶Åüü¢ AVAssetReader copyNextSampleBuffer cost: \((endTime - beginTime) * 1000) ms")
            let curSampleTime = CMSampleBufferGetOutputPresentationTimeStamp(buffer)
            if CMTIME_IS_INVALID(curSampleTime) {
                continue
            }
            
            // ÊâæÂà∞‰∫ÜÁõÆÊ†áÊó∂Èó¥ÂØπÂ∫îÁöÑÂ∏ß
            if isMatchFrame(targetTime: correctTime, decodeTime: curSampleTime) {
                let time = CMTimeGetSeconds(curSampleTime)
                currentDecodeTime = time
                decodeBuffer = buffer
                return buffer
            }
        }
        
        return nil
    }
    
    /// Ê∏ÖÁêÜËµÑÊ∫ê
    func clear() {
        // asset?.cancelLoading()
        decodeBuffer = nil
        decodeTexture = nil
        // TODO: MTLTextureCacheÂÆûÈôÖ‰ΩøÁî®‰∏≠ÂèØËÉΩÈúÄË¶ÅÈáäÊîæ
        reader?.cancelReading()
        reader = nil
        videoTrack = nil
        videoTrackOutput = nil
    }
}

// MARK: - Private Methods
extension VideoDecoder {
    
    /// Ê†πÊçÆÈúÄË¶ÅÈáçÊñ∞ÂàõÂª∫AVAssetReader
    func createNewReader(_ startTime: Double) {
        let beginTime = CFAbsoluteTimeGetCurrent()
        defer {
            let end = CFAbsoluteTimeGetCurrent()
            print("ü¶Å createNewMeta ÂàõÂª∫Ëß£Á†ÅÂô®ËÄóÊó∂ cost: \((end - beginTime) * 1000) ms")
        }
        resetEnv()
        guard let asset = asset else {
            return
        }
        
        do {
            try reader = AVAssetReader(asset: asset)
            var bufferWidth = outputSize.width
            var bufferHeight = outputSize.height
            if let meta = self.meta, meta.rotation % 180 != 0 {
                bufferWidth = outputSize.height
                bufferHeight = outputSize.width
            }

            let outputOptions: [String: Any] = [
                kCVPixelBufferOpenGLESCompatibilityKey as String: true,
                kCVPixelBufferIOSurfacePropertiesKey as String: [:],
                kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange,
//                kCVPixelBufferWidthKey as String: Int(bufferWidth),
//                kCVPixelBufferHeightKey as String: Int(bufferHeight)
            ]
            self.outputSetting = outputOptions

            // ÈªòËÆ§‰ΩøÁî®ËßÜÈ¢ëËΩ®ÈÅìÈªòËÆ§ÁöÑÊó∂Èó¥Âü∫Ôºå‰øùËØÅÂêéÁª≠PTS‰ΩøÁî®ÁöÑÊó∂ÂÄôÊó∂Èó¥Âü∫‰∏ÄËá¥
            let timescale = videoTrack?.naturalTimeScale ?? asset.duration.timescale
            let pos = CMTimeMakeWithSeconds(startTime, preferredTimescale: timescale)
            let duration = CMTime.positiveInfinity
            self.reader?.timeRange = CMTimeRangeMake(start: pos, duration: duration)

            if let track = videoTrack {
                let output = AVAssetReaderTrackOutput(track: track, outputSettings: outputSetting)
                output.alwaysCopiesSampleData = false
                videoTrackOutput = output
                if reader?.canAdd(output) == true {
                    reader?.add(output)
                }
            }
            
            if reader?.startReading() == false {
                if let error = reader?.error {
                    print("ü¶Å startReading error = \(error)")
                } else {
                    print("ü¶Å startReading error = Nil")
                }
            }
            
        } catch {
            let frameRate = videoTrack?.nominalFrameRate ?? 0
            let isReadable = self.asset?.isReadable ?? false
            print("ü¶Å createNewReader error = \(error.localizedDescription) - frameRate = \(frameRate) - isReadable = \(isReadable)")
        }
    }
    
    func resetEnv() {
        self.reader?.cancelReading()
        self.videoTrackOutput = nil
        self.reader = nil
        
        /*if self.videoTrack?.nominalFrameRate == 0,
           let meta = MediaMetaCache.shared.createNewMeta(self.uri, isVideo: true) {
            self.asset = meta.videoAsset
            self.videoTrack = meta.videoTrack
        }*/
        if self.asset?.isReadable == false,
           let meta = cache.createNewMeta(self.uri, isVideo: true) {
            self.asset = meta.videoAsset
            self.videoTrack = meta.videoTrack
        }
    }
    
    // ËÆ°ÁÆóÂΩìÂâçÁõÆÊ†áÊó∂Èó¥ÂíåËß£Á†ÅÊó∂Èó¥ÊòØÂê¶ÂåπÈÖç
    func isMatchFrame(targetTime: Double, decodeTime: CMTime) -> Bool {
        
        // ------------ „ÄêÂÖúÂ∫ïÁöÑÊñπÊ°à„ÄëÔºàv1.5.00‰ª•ÂâçÁöÑÂåπÈÖçËßÑÂàôÔºâ------------

        // Â¶ÇÊûúÁõ∏Á≠âÔºåÁõ¥Êé•ÂåπÈÖçÊàêÂäü
        if CGFloat.equal(targetTime, decodeTime.seconds, precise: 5) {
            return true
        }
        
        let time = CMTimeGetSeconds(decodeTime)
        let decodeMatch = Double.compare(targetTime, by: >, time, precise: 5)
        let diff = Double.compare(abs(targetTime - time), by: <, self.oneFrameTime, precise: 5)
        if decodeMatch, diff {
            return true
        }
        
        // ÊâæÂà∞‰∫ÜÁõÆÊ†áÊó∂Èó¥ÂØπÂ∫îÁöÑÂ∏ß
        let offsetTime2 = abs(targetTime - time) <= (self.oneFrameTime)
        let isLastFrame = (self.assetDuration - targetTime) <= (self.oneFrameTime)
        return isLastFrame && offsetTime2
    }

}

extension AVAsset {
    
    @discardableResult
    func syncLoadTracks() -> NSError? {
        let beginTime = CFAbsoluteTimeGetCurrent()
        defer {
            let end = CFAbsoluteTimeGetCurrent()
            print("ü¶Å syncLoadTracks cost: \((end - beginTime) * 1000) ms")
        }
        let trackKey = "tracks"
        let sema = DispatchSemaphore(value: 0)
        var error: NSError?
        self.loadValuesAsynchronously(forKeys: [trackKey]) {
            let status = self.statusOfValue(forKey: trackKey, error: &error)
            if status == .loaded || status == .cancelled || status == .failed {
                sema.signal()
            }
        }
        sema.wait()
        if let error = error {
            print("syncLoadTracks \(error) \(self)")
            if let url = (self as? AVURLAsset)?.url.relativePath {
                let fileExists = FileManager.default.fileExists(atPath: url)
                print("syncLoadTracks fileExists:\(fileExists), \(url)")
            }
        }
        return error
    }
    
}

