//
//  VideoDecoder.swift
//  Aries
//
//  Created by liangwei on 2023/3/7.
//  Copyright Â© 2023 Pinguo. All rights reserved.
//

import UIKit
import AVFoundation

/// è§†é¢‘è§£ç å™¨
class VideoDecoder {
    
    static let device = MTLCreateSystemDefaultDevice()
    
    /// è§†é¢‘è§£ç ç›¸å…³å±žæ€§
    private var asset: AVAsset?
    private var videoTrack: AVAssetTrack?
    private var videoOriginalFPS: CGFloat

    private var reader: AVAssetReader?
    private var videoTrackOutput: AVAssetReaderTrackOutput?
    private var outputSetting: [String: Any] = [:]
        
    /// å‰ä¸€æ¬¡decodeæˆåŠŸçš„æ—¶é—´æˆ³
    private var latestDecodeTime: Double = -1
    
    /// å½“å‰éœ€è¦decodeçš„æ—¶é—´æˆ³
    private var currentDecodeTime: Double = -1
    
    /// æ ‡è®°ä¿®æ”¹äº†è§£ç å™¨è¾“å‡ºå°ºå¯¸ï¼Œä¸‹æ¬¡è§£ç æ—¶éœ€è¦é‡å»ºè§£ç å™¨
    private var outputSizeChanged: Bool = false
    
    /// èµ„æºæ—¶é•¿
    private(set) var assetDuration: Double = 0
    
    private(set) var decodeBuffer: CMSampleBuffer?
    
    private var decodeTexture: MTLTexture?
    
    private var identifier: String
    
    private var uri: String
        
    /// ä¸€å¸§çš„æ—¶é•¿
    let oneFrameTime: Double
    
    lazy var textureCache: CVMetalTextureCache? = {
        var cache: CVMetalTextureCache?
        CVMetalTextureCacheCreate(kCFAllocatorDefault, nil, Self.device!, nil, &cache)
        return cache
    }()
    
    /// è§£ç è¾“å‡ºå°ºå¯¸
    var outputSize: CGSize = .zero
    
    var meta: MediaMeta? {
        return MediaMetaCache.shared.meta(for: uri, isVideo: true)
    }
    
    // MARK: Initialized Method
    required init(uri: String, key: String) {
        self.uri = uri
        identifier = key
        oneFrameTime = 1.0 / CGFloat(30)
        if let meta = MediaMetaCache.shared.meta(for: uri, isVideo: true) {
            asset = meta.videoAsset
            videoTrack = meta.videoTrack
            let nominalFrameRate = CGFloat(videoTrack?.nominalFrameRate ?? 0)
            if nominalFrameRate > 0 {
                /// æŸäº›è§†é¢‘nominalFrameRateè¯»å‡ºæ¥è§†é¢‘å¸§çŽ‡29.99998ä¸å‡†ç¡®ï¼Œdecodeæ–¹æ³•ä¸­ä½¿ç”¨videoOriginalFPSå‘ä¸‹å¡å¸§å¯¼è‡´0.03333333333333è¢«å¡æˆç¬¬0å¸§ï¼Œå¯¼è‡´è§£ç ç”»é¢å’Œè§†é¢‘ç”»é¢ä¸ä¸€è‡´
                videoOriginalFPS = nominalFrameRate.precised(3)
            }
            else {
                videoOriginalFPS = CGFloat(30)
            }

            if let track = videoTrack {
                assetDuration = track.timeRange.duration.seconds
            }
        }
        else {
            videoOriginalFPS = CGFloat(30)
        }
        outputSize = meta?.realSize ?? .zero
    }
    
    
    deinit {
        clear()
        print("ðŸ¤– VideoDecoder deinit.")
    }
    
    func updateOutputSize(_ size: CGSize) {
        guard !size.equalTo(outputSize) else {
            return
        }
        
        decodeTexture = nil
        outputSize = size
        outputSizeChanged = true
    }

    /// è§£ç æŒ‡å®šä½ç½®çš„å¸§æ•°æ®å°è£…æˆMTLTextureè¿›è¡Œè¿”å›ž
    /// - Parameter targetTime: å¾…è§£ç ä½ç½®
    /// - Returns: æŒ‡å®šä½ç½®çš„å¸§æ•°æ®çº¹ç†ä¿¡æ¯
    func decode(_ targetTime: Double) -> CMSampleBuffer? {
        let targetTime: CGFloat = targetTime
        guard !outputSize.equalTo(.zero) else {
            return nil
        }
        
        // åœ¨åŠ¨æ€å¸§çŽ‡çš„æƒ…å†µä¸‹ï¼Œäº§ç”Ÿçš„è’™ç‰ˆè§†é¢‘å¹³å‡å¸§çŽ‡å’Œè§†é¢‘æœ‰è¯¯å·®ï¼Œå‘ä¸‹å¡å¸§å¯ä»¥é¿å…ç»å¤§éƒ¨åˆ†çš„è¯¯å·®æƒ…å†µ
        let correctTime = targetTime > 0.0 ? targetTime.floorMatchFrameValue(fps: videoOriginalFPS) : 0.0
        
        objc_sync_enter(self)
        let startTime = CFAbsoluteTimeGetCurrent()
        defer {
            objc_sync_exit(self)
            let endTime = CFAbsoluteTimeGetCurrent()
            print("ðŸ¦ decode time: \(targetTime) | cost: \((endTime - startTime) * 1000)ms")
        }
        
        // æ˜¯å¦æ˜¯åœ¨å¾€å‰(å¾€å³)æ»‘åŠ¨ - å€’ç€æ»‘åŠ¨
        let isForward = latestDecodeTime > correctTime
        // å¦‚æžœå’Œä¸Šæ¬¡å·²è§£ç æ—¶é—´ç›¸ç­‰ï¼Œåˆ™ç›´æŽ¥è¿”å›žä¸Šæ¬¡çš„çº¹ç†
        if latestDecodeTime == correctTime, let curTexture = decodeTexture {
            return decodeBuffer
        }
        /* ä»¥ä¸‹å‡ ç§æƒ…å†µéœ€è¦é‡æ–°æž„é€ è§£ç å™¨
           1. -1: è¡¨ç¤ºç¬¬ä¸€æ¬¡è¿›å…¥è§£ç 
           2. isForward: è¡¨ç¤ºå€’æ”¾éœ€è¦é‡æ–°å¼€å§‹è§£ç 
           3. outputSizeChanged: è¡¨ç¤ºé¢„è§ˆå°ºå¯¸è¢«ä¿®æ”¹
           4. æ˜¯å¦è¢«ç³»ç»Ÿä¸­æ–­
           5. å¼‚å¸¸ä¸‹è§£ç å™¨æ²¡åˆ›å»º
           6. å¾…è§£ç ä½ç½®å’Œå½“å‰è§†é¢‘çœŸå®žè§£ç ä½ç½®è¶…è¿‡2s */
        var interuptBySys: Bool = false
        if let error = self.reader?.error as? NSError, error.code == -11847 {
            interuptBySys = true
        }
        
        if latestDecodeTime == -1 ||
            isForward ||
            outputSizeChanged ||
            interuptBySys ||
            reader?.status == .failed ||
            (correctTime - latestDecodeTime) >= 2.0 {
            // åˆ›å»ºæ—¶ï¼Œå‘å‰å¤šè®¾ç½®ä¸€å¸§
            var startTime = (correctTime - oneFrameTime) > 0 ? (correctTime - oneFrameTime) : 0.0
            if self.assetDuration - targetTime < 0.5 {
                startTime = (startTime - 0.5) > 0 ? (startTime - 0.5) : 0.0
            }
            
            createNewReader(startTime)
            self.decodeBuffer = nil
            outputSizeChanged = false
        }
        
        guard let track = videoTrack else {
            return nil
        }
        
        latestDecodeTime = correctTime
        // æ˜¯å¦ä½¿ç”¨ç›¸åŒå¸§
        var useSameBuffer: Bool = false
        if let curBuffer = decodeBuffer {
            let curSampleTime: CMTime = CMSampleBufferGetOutputPresentationTimeStamp(curBuffer)
            if CMTIME_IS_INVALID(curSampleTime) {
                useSameBuffer = false
            }
            // å¦‚æžœå½“å‰bufferæ—¶é—´å¤§äºŽç›®æ ‡æ—¶é—´ï¼Œæˆ–è€…æ˜¯å½“å‰æ˜¯æœ€åŽä¸€å¸§ï¼Œå¹¶ä¸”å½“å‰bufferçš„æ—¶é—´å’Œç›®å‰ç›¸å·®ä¸è¶…è¿‡1å¸§ï¼Œå°±ä½¿ç”¨å½“å‰å¸§
            if isMatchFrame(targetTime: correctTime, decodeTime: curSampleTime) {
                useSameBuffer = true
            }
        }
        
        if useSameBuffer {
            return decodeBuffer
        }

        guard let reader = self.reader, let output = self.videoTrackOutput else {
            return nil
        }
        
        while reader.status == .reading && track.nominalFrameRate > 0 {
            guard let buffer = output.copyNextSampleBuffer() else {
                break
            }
            let curSampleTime = CMSampleBufferGetOutputPresentationTimeStamp(buffer)
            if CMTIME_IS_INVALID(curSampleTime) {
                continue
            }
            
            // æ‰¾åˆ°äº†ç›®æ ‡æ—¶é—´å¯¹åº”çš„å¸§
            if isMatchFrame(targetTime: correctTime, decodeTime: curSampleTime) {
                let time = CMTimeGetSeconds(curSampleTime)
                currentDecodeTime = time
                decodeBuffer = buffer
                return buffer
            }
        }
        
        return nil
    }
    
    /// æ¸…ç†èµ„æº
    func clear() {
        // asset?.cancelLoading()
        decodeBuffer = nil
        decodeTexture = nil
        // TODO: MTLTextureCacheå®žé™…ä½¿ç”¨ä¸­å¯èƒ½éœ€è¦é‡Šæ”¾
        reader?.cancelReading()
        reader = nil
        videoTrack = nil
        videoTrackOutput = nil
    }
}

// MARK: - Private Methods
private extension VideoDecoder {
    
    /// æ ¹æ®éœ€è¦é‡æ–°åˆ›å»ºAVAssetReader
    func createNewReader(_ startTime: Double) {
        resetEnv()
        guard let asset = asset else {
            return
        }
        
        do {
            try reader = AVAssetReader(asset: asset)
            var bufferWidth = outputSize.width
            var bufferHeight = outputSize.height
            if let meta = self.meta, meta.rotation % 180 != 0 {
                bufferWidth = outputSize.height
                bufferHeight = outputSize.width
            }

            let outputOptions: [String: Any] = [
                kCVPixelBufferOpenGLESCompatibilityKey as String: true,
                kCVPixelBufferIOSurfacePropertiesKey as String: [:],
                kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange,
//                kCVPixelBufferWidthKey as String: Int(bufferWidth),
//                kCVPixelBufferHeightKey as String: Int(bufferHeight)
            ]
            self.outputSetting = outputOptions

            // é»˜è®¤ä½¿ç”¨è§†é¢‘è½¨é“é»˜è®¤çš„æ—¶é—´åŸºï¼Œä¿è¯åŽç»­PTSä½¿ç”¨çš„æ—¶å€™æ—¶é—´åŸºä¸€è‡´
            let timescale = videoTrack?.naturalTimeScale ?? asset.duration.timescale
            let pos = CMTimeMakeWithSeconds(startTime, preferredTimescale: timescale)
            let duration = CMTime.positiveInfinity
            self.reader?.timeRange = CMTimeRangeMake(start: pos, duration: duration)

            if let track = videoTrack {
                let output = AVAssetReaderTrackOutput(track: track, outputSettings: outputSetting)
                output.alwaysCopiesSampleData = false
                videoTrackOutput = output
                if reader?.canAdd(output) == true {
                    reader?.add(output)
                }
            }
            
            if reader?.startReading() == false {
                if let error = reader?.error {
                    print("ðŸ¦ startReading error = \(error)")
                } else {
                    print("ðŸ¦ startReading error = Nil")
                }
            }
            
        } catch {
            let frameRate = videoTrack?.nominalFrameRate ?? 0
            let isReadable = self.asset?.isReadable ?? false
            print("ðŸ¦ createNewReader error = \(error.localizedDescription) - frameRate = \(frameRate) - isReadable = \(isReadable)")
        }
    }
    
    func resetEnv() {
        self.reader?.cancelReading()
        self.videoTrackOutput = nil
        self.reader = nil
        
        /*if self.videoTrack?.nominalFrameRate == 0,
           let meta = MediaMetaCache.shared.createNewMeta(self.uri, isVideo: true) {
            self.asset = meta.videoAsset
            self.videoTrack = meta.videoTrack
        }*/
        if self.asset?.isReadable == false,
           let meta = MediaMetaCache.shared.createNewMeta(self.uri, isVideo: true) {
            self.asset = meta.videoAsset
            self.videoTrack = meta.videoTrack
        }
    }
    
    // è®¡ç®—å½“å‰ç›®æ ‡æ—¶é—´å’Œè§£ç æ—¶é—´æ˜¯å¦åŒ¹é…
    func isMatchFrame(targetTime: Double, decodeTime: CMTime) -> Bool {
        
        // ------------ ã€å…œåº•çš„æ–¹æ¡ˆã€‘ï¼ˆv1.5.00ä»¥å‰çš„åŒ¹é…è§„åˆ™ï¼‰------------

        // å¦‚æžœç›¸ç­‰ï¼Œç›´æŽ¥åŒ¹é…æˆåŠŸ
        if CGFloat.equal(targetTime, decodeTime.seconds, precise: 5) {
            return true
        }
        
        let time = CMTimeGetSeconds(decodeTime)
        let decodeMatch = Double.compare(targetTime, by: >, time, precise: 5)
        let diff = Double.compare(abs(targetTime - time), by: <, self.oneFrameTime, precise: 5)
        if decodeMatch, diff {
            return true
        }
        
        // æ‰¾åˆ°äº†ç›®æ ‡æ—¶é—´å¯¹åº”çš„å¸§
        let offsetTime2 = abs(targetTime - time) <= (self.oneFrameTime)
        let isLastFrame = (self.assetDuration - targetTime) <= (self.oneFrameTime)
        return isLastFrame && offsetTime2
    }

}

extension AVAsset {
    
    @discardableResult
    func syncLoadTracks() -> NSError? {
        let trackKey = "tracks"
        let sema = DispatchSemaphore(value: 0)
        var error: NSError?
        self.loadValuesAsynchronously(forKeys: [trackKey]) {
            let status = self.statusOfValue(forKey: trackKey, error: &error)
            if status == .loaded || status == .cancelled || status == .failed {
                sema.signal()
            }
        }
        sema.wait()
        if let error = error {
            print("syncLoadTracks \(error) \(self)")
            if let url = (self as? AVURLAsset)?.url.relativePath {
                let fileExists = FileManager.default.fileExists(atPath: url)
                print("syncLoadTracks fileExists:\(fileExists), \(url)")
            }
        }
        return error
    }
    
}

